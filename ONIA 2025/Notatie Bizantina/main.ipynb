{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
	"# This is the solution that got 51 points\n",
        "!wget https://judge.nitro-ai.org/download/roai-2025/onia/2/custom_archive.zip\n",
        "!unzip /content/custom_archive.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpzhBpP_YGaj",
        "outputId": "035c06f6-b2e6-45e6-eaf8-9da8e1855344"
      },
      "execution_count": 1,
      "outputs": []
    },

    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "XyKzz7vusGIR"
      },
      "outputs": [],
      "source": [
        "# Solution scaffolding for 'Notatia bizantina'\n",
        "# Feel free to use anything from this\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import csv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import torch._dynamo\n",
        "torch._dynamo.disable()\n",
        "\n",
        "from typing import List, Tuple\n",
        "import os\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation transforms\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomRotation(10),                       # small rotations\n",
        "    transforms.RandomAffine(0, translate=(0.1, 0.1)),   # small shifts\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),# brightness/contrast\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "eval_transforms = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "jFv6z5u2dkMU"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeeperCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(DeeperCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),   # 48x48 -> 48x48\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),                           # 24x24\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # 24x24 -> 24x24\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),                           # 12x12\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1), # 12x12 -> 12x12\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),                           # 6x6\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),# 6x6 -> 6x6\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AdaptiveAvgPool2d((1, 1))                  # 1x1\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)  # flatten to (batch, features)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "UuTDfX0KaQ2P"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN model\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.fc1 = nn.Linear(64*12*12, 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64*12*12)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "LOpNoqdgdxrd"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset class\n",
        "class NeumeDataset(Dataset):\n",
        "    def __init__(self, csv_path: str, root_dir: str, label_map: dict, train=True):\n",
        "        self.data = pd.read_csv(csv_path)\n",
        "        self.root_dir = root_dir\n",
        "        self.label_map = label_map\n",
        "        self.train = train\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        path = f\"{self.root_dir}/{row['Path']}\"\n",
        "        img = cv2.imread(path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        img = cv2.resize(img, (48, 48))\n",
        "\n",
        "        if self.train:\n",
        "            img = train_transforms(img)\n",
        "        else:\n",
        "            img = eval_transforms(img)\n",
        "\n",
        "        label = self.label_map[row['Effect']]\n",
        "        return img, torch.tensor(label, dtype=torch.long)"
      ],
      "metadata": {
        "id": "Kxbj1tT3tfdY"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(img):\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img = cv2.resize(img, (48, 48))\n",
        "    img = img.astype(np.float32) / 255.0  # normalize to [0,1]\n",
        "    img = np.expand_dims(img, axis=0)     # for channel dimension\n",
        "    return img"
      ],
      "metadata": {
        "id": "cl-uEbQjtlpr"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utils\n",
        "\n",
        "def load_data(csv_path: str, root_dir: str) -> Tuple[List, List, dict]:\n",
        "    df = pd.read_csv(csv_path)\n",
        "    unique_labels = sorted(df['Effect'].unique())\n",
        "    label_map = {label: i for i, label in enumerate(unique_labels)}\n",
        "    return df, label_map\n",
        "\n",
        "def train_model(train_csv, root_dir):\n",
        "    df, label_map = load_data(train_csv, root_dir)\n",
        "    dataset = NeumeDataset(train_csv, root_dir, label_map)\n",
        "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "    # model = SimpleCNN(num_classes=len(label_map))\n",
        "    model = DeeperCNN(num_classes=len(label_map))\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(100):\n",
        "        for imgs, labels in dataloader:\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(f\"Epoch {epoch+1} Loss: {loss.item():.4f}\")\n",
        "\n",
        "    return model, label_map"
      ],
      "metadata": {
        "id": "PtyVIXi9tn0o"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process eval images\n",
        "\n",
        "\n",
        "# Preprocess and extract signs from sequence dataset\n",
        "def process_sequence_image(model, label_map, path):\n",
        "    img = cv2.imread(path)\n",
        "    if img is None:\n",
        "        print(f\"!!! {path}\")\n",
        "        return []\n",
        "\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Detect bounding boxes for individual neumes\n",
        "    _, thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    boxes = [cv2.boundingRect(c) for c in contours]\n",
        "    boxes = sorted(boxes, key=lambda b: b[0])  # left to right\n",
        "\n",
        "    sequence = []\n",
        "    inv_label_map = {v: k for k, v in label_map.items()}\n",
        "    pitch = 0\n",
        "\n",
        "    model.eval()\n",
        "    for (x, y, w, h) in boxes:\n",
        "        neum_img = gray[y:y+h, x:x+w]\n",
        "        neum_img = cv2.resize(neum_img, (48, 48))\n",
        "        neum_img = eval_transforms(neum_img).unsqueeze(0).to(device)\n",
        "\n",
        "        output = model(neum_img)\n",
        "        pred_label = torch.argmax(output, dim=1).item()\n",
        "        pred_effect = inv_label_map[pred_label]\n",
        "\n",
        "        if pred_effect not in ['A', 'B']:\n",
        "            pitch += int(pred_effect)\n",
        "        sequence.append(pitch)\n",
        "\n",
        "    return sequence"
      ],
      "metadata": {
        "id": "-9x1LZxxtp-a"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict\n",
        "\n",
        "eval_root = \"/content/starting_kit\"\n",
        "# Make predictions and output them to output.csv\n",
        "def predict(model, label_map):\n",
        "    results = []\n",
        "    with open(\"/content/starting_kit/dataset_eval.csv\", \"r\", encoding=\"utf-8\") as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            image_path = os.path.join(eval_root, row[\"datapointID\"])\n",
        "            ans_seq = process_sequence_image(model, label_map, image_path)\n",
        "            results.append({\n",
        "                \"subtaskID\": 1,\n",
        "                \"datapointID\": row[\"datapointID\"],\n",
        "                \"answer\": \"|\".join(map(str, ans_seq))\n",
        "            })\n",
        "\n",
        "    with open(\"output.csv\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"subtaskID,datapointID,answer\\n\")\n",
        "        for res in results:\n",
        "            f.write(f\"{res['subtaskID']},{res['datapointID']},{res['answer']}\\n\")"
      ],
      "metadata": {
        "id": "z9HP3DRHtsht"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    model, label_map = train_model(\"/content/starting_kit/dataset_train.csv\", \"/content/starting_kit\")\n",
        "    predict(model, label_map)\n",
        "    print(\"Done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtpQqShntstv",
        "outputId": "2714e4d5-ab3f-4548-afbe-812f88c1d201"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss: 1.8164\n",
            "Epoch 2 Loss: 1.5655\n",
            "Epoch 3 Loss: 1.3639\n",
            "Epoch 4 Loss: 1.2635\n",
            "Epoch 5 Loss: 0.9777\n",
            "Epoch 6 Loss: 0.8921\n",
            "Epoch 7 Loss: 0.7672\n",
            "Epoch 8 Loss: 0.5870\n",
            "Epoch 9 Loss: 0.3922\n",
            "Epoch 10 Loss: 0.6098\n",
            "Epoch 11 Loss: 0.3818\n",
            "Epoch 12 Loss: 0.5902\n",
            "Epoch 13 Loss: 0.4165\n",
            "Epoch 14 Loss: 0.2201\n",
            "Epoch 15 Loss: 0.1628\n",
            "too long...\n",
            "Epoch 95 Loss: 0.0014\n",
            "Epoch 96 Loss: 0.0030\n",
            "Epoch 97 Loss: 0.0153\n",
            "Epoch 98 Loss: 0.0489\n",
            "Epoch 99 Loss: 0.0024\n",
            "Epoch 100 Loss: 0.0042\n",
            "Done\n"
          ]
        }
      ]
    }
  ]
}